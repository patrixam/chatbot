{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIqD3bXk4mDu7GjgRZdnid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrixam/chatbot/blob/main/notebooks/proyecto_apoyo/Basado_Reglas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BASADO EN REGLAS (BIBLIOTECA EXPERTA)"
      ],
      "metadata": {
        "id": "I4UAnrtajC20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install experta\n",
        "!pip install frozendict==2.3.4"
      ],
      "metadata": {
        "id": "E5RPAE_AjLsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ejemplos base"
      ],
      "metadata": {
        "id": "DqiHeTfG3H4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import Fact, Rule, KnowledgeEngine\n",
        "\n",
        "#Fact: Define hechos, que son las piezas de información con las que el sistema trabaja.\n",
        "#Rule: Representa reglas que relacionan ciertos hechos con conclusiones o acciones.\n",
        "#KnowledgeEngine: Es el motor que procesa las reglas y los hechos.\n",
        "\n",
        "# Definir hechos\n",
        "class Diagnostico(Fact):\n",
        "    \"\"\"\n",
        "    Representa los síntomas del dispositivo.\n",
        "    Los hechos contienen información específica sobre el estado del dispositivo.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "# Motor de conocimiento\n",
        "class MotorDiagnostico(KnowledgeEngine):\n",
        "    \"\"\"\n",
        "    Motor de reglas para diagnosticar problemas en un dispositivo\n",
        "    basado en los síntomas declarados.\n",
        "    \"\"\"\n",
        "\n",
        "    @Rule(Diagnostico(no_enciende=True, luces_apagadas=True))\n",
        "    def cable_alimentacion(self):\n",
        "        \"\"\"\n",
        "        Regla que se activa cuando el dispositivo no enciende y las luces están apagadas.\n",
        "        \"\"\"\n",
        "        print(\"Diagnóstico: Revisar el cable de alimentación.\")\n",
        "\n",
        "# Crear una instancia del motor de diagnóstico\n",
        "motor = MotorDiagnostico()\n",
        "\n",
        "# Reiniciar el motor (limpia cualquier estado previo o hechos declarados)\n",
        "motor.reset()\n",
        "\n",
        "# Declarar hechos en el motor\n",
        "# Estos hechos representan los síntomas observados en el dispositivo\n",
        "motor.declare(Diagnostico(no_enciende=True, luces_apagadas=True))\n",
        "\n",
        "# Ejecutar el motor para procesar las reglas basadas en los hechos declarados\n",
        "motor.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0cQ1czrc2c4",
        "outputId": "bf7fef13-98a0-4876-97a7-4802871d9bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnóstico: Revisar el cable de alimentación.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import *\n",
        "\n",
        "class Diagnostico(Fact):\n",
        "    \"\"\"Representa los síntomas reportados.\"\"\"\n",
        "    pass\n",
        "\n",
        "class SistemaDomestico(KnowledgeEngine):\n",
        "\n",
        "    # Regla 1: Problema de energía\n",
        "    @Rule(Diagnostico(falla=\"no enciende\", dispositivo=\"televisor\"))\n",
        "    def verificar_energia_televisor(self):\n",
        "        print(\"Verifica si el televisor está enchufado y la toma de corriente funciona.\")\n",
        "\n",
        "    # Regla 2: Problema de pantalla negra\n",
        "    @Rule(Diagnostico(falla=\"pantalla negra\", dispositivo=\"ordenador\"))\n",
        "    def revisar_pantalla_ordenador(self):\n",
        "        print(\"Prueba cambiar el cable HDMI o la pantalla del ordenador.\")\n",
        "\n",
        "    # Regla 3: Problema de conexión a internet\n",
        "    @Rule(Diagnostico(falla=\"sin internet\", dispositivo=\"router\", indicador=\"luz roja\"))\n",
        "    def verificar_router(self):\n",
        "        print(\"Reinicia el router y verifica la configuración de red.\")\n",
        "\n",
        "    # Regla 4: Problema de rendimiento\n",
        "    @Rule(Diagnostico(falla=\"dispositivo lento\", dispositivo=\"móvil\"))\n",
        "    def optimizar_moviles(self):\n",
        "        print(\"Cierra aplicaciones en segundo plano y reinicia el dispositivo móvil.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Sistema de Diagnóstico Doméstico ===\")\n",
        "\n",
        "    # Crear instancia del motor\n",
        "    engine = SistemaDomestico()\n",
        "    engine.reset()\n",
        "\n",
        "    # Declarar hechos\n",
        "    engine.declare(Diagnostico(falla=\"no enciende\", dispositivo=\"televisor\"))\n",
        "    engine.declare(Diagnostico(falla=\"pantalla negra\", dispositivo=\"ordenador\"))\n",
        "    engine.declare(Diagnostico(falla=\"sin internet\", dispositivo=\"router\", indicador=\"luz roja\"))\n",
        "\n",
        "    # Ejecutar motor\n",
        "    engine.run()\n",
        "    print(\"=== Diagnóstico Completado ===\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcnjWwxljFan",
        "outputId": "a7b69389-2071-4181-ec62-b02d1df9e062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sistema de Diagnóstico Doméstico ===\n",
            "Reinicia el router y verifica la configuración de red.\n",
            "Prueba cambiar el cable HDMI o la pantalla del ordenador.\n",
            "Verifica si el televisor está enchufado y la toma de corriente funciona.\n",
            "=== Diagnóstico Completado ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Combinación con PLN"
      ],
      "metadata": {
        "id": "dsnD2GvpfzeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import KnowledgeEngine, Fact, Rule, MATCH\n",
        "from transformers import pipeline\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1) Definimos el hecho que contendrá\n",
        "#    la pregunta, la etiqueta y la confianza.\n",
        "# ------------------------------------------\n",
        "class PreguntaUsuario(Fact):\n",
        "    \"\"\"\n",
        "    Hecho (Fact) que representa la pregunta y su clasificación.\n",
        "    Campos:\n",
        "    - texto: contenido original de la pregunta\n",
        "    - etiqueta: categoría/intención principal devuelta por el PLN\n",
        "    - score: confianza asociada\n",
        "    \"\"\"\n",
        "    texto = Field(str, mandatory=True)\n",
        "    etiqueta = Field(str, default=None)\n",
        "    score = Field(float, default=0.0)\n",
        "\n",
        "# ------------------------------------------\n",
        "# 2) Motor de Reglas con Experta\n",
        "# ------------------------------------------\n",
        "class MotorDeReglasFAQ(KnowledgeEngine):\n",
        "    \"\"\"\n",
        "    Motor de Reglas que decide la respuesta en función de la etiqueta\n",
        "    y la confianza devuelta por el modelo de clasificación.\n",
        "    \"\"\"\n",
        "\n",
        "    @Rule(\n",
        "        PreguntaUsuario(etiqueta=\"Horario\", score=MATCH.score_pln),\n",
        "        # Salience define prioridad (opcional)\n",
        "        salience=10\n",
        "    )\n",
        "    def regla_horario(self, score_pln):\n",
        "        # Ejemplo: si la confianza es mayor a 0.7, tomamos la respuesta de FAQ\n",
        "        if score_pln >= 0.7:\n",
        "            print(\"Regla disparada: Horario (FAQ).\")\n",
        "            self.declare(Fact(\n",
        "                respuesta_final=\"Nuestro horario es de lunes a viernes, de 09:00 a 18:00.\"\n",
        "            ))\n",
        "            self.halted = True\n",
        "\n",
        "    @Rule(\n",
        "        PreguntaUsuario(etiqueta=\"Devoluciones\", score=MATCH.score_pln),\n",
        "        salience=10\n",
        "    )\n",
        "    def regla_devoluciones(self, score_pln):\n",
        "        if score_pln >= 0.7:\n",
        "            print(\"Regla disparada: Devoluciones (FAQ).\")\n",
        "            self.declare(Fact(\n",
        "                respuesta_final=\"Aceptamos devoluciones hasta 30 días después de la compra.\"\n",
        "            ))\n",
        "            self.halted = True\n",
        "\n",
        "    @Rule(\n",
        "        PreguntaUsuario(etiqueta=\"Envíos\", score=MATCH.score_pln),\n",
        "        salience=10\n",
        "    )\n",
        "    def regla_envios(self, score_pln):\n",
        "        if score_pln >= 0.7:\n",
        "            print(\"Regla disparada: Envíos (FAQ).\")\n",
        "            self.declare(Fact(\n",
        "                respuesta_final=\"Los envíos demoran entre 2 y 5 días laborables, según la ubicación.\"\n",
        "            ))\n",
        "            self.halted = True\n",
        "\n",
        "    @Rule(\n",
        "        PreguntaUsuario(etiqueta=\"Pagos\", score=MATCH.score_pln),\n",
        "        salience=10\n",
        "    )\n",
        "    def regla_pagos(self, score_pln):\n",
        "        if score_pln >= 0.7:\n",
        "            print(\"Regla disparada: Pagos (FAQ).\")\n",
        "            self.declare(Fact(\n",
        "                respuesta_final=\"Aceptamos diversas formas de pago, incluyendo PayPal y tarjetas de crédito.\"\n",
        "            ))\n",
        "            self.halted = True\n",
        "\n",
        "    # Regla fallback: si nada ha disparado respuesta_final, o la confianza < 0.7\n",
        "    @Rule(\n",
        "        PreguntaUsuario(score=MATCH.score_pln),\n",
        "        NOT(Fact(respuesta_final=W())),  # No existe ningún hecho con 'respuesta_final'\n",
        "        salience=-1                      # Baja prioridad\n",
        "        )\n",
        "    def regla_fallback(self, score_pln):\n",
        "        \"\"\"\n",
        "        Si llegamos aquí, significa que no hay ninguna regla de FAQ que coincida\n",
        "        o la confianza es baja. Devolvemos una respuesta genérica.\n",
        "        \"\"\"\n",
        "        print(\"Regla fallback activada.\")\n",
        "        mensaje = (\n",
        "            \"Lo siento, no tengo una respuesta clara a tu pregunta. \"\n",
        "            \"Por favor, contáctanos directamente para más información.\"\n",
        "        )\n",
        "        self.declare(Fact(respuesta_final=mensaje))\n",
        "        self.halted = True\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3) Función para clasificar y aplicar reglas\n",
        "# ------------------------------------------\n",
        "def procesar_pregunta(pregunta):\n",
        "    \"\"\"\n",
        "    1) Usamos un pipeline de zero-shot classification en español para etiquetar la pregunta.\n",
        "    2) Cargamos el motor de reglas y le pasamos los hechos (pregunta, etiqueta, score).\n",
        "    3) Retornamos la respuesta final.\n",
        "    \"\"\"\n",
        "\n",
        "    # Lista de etiquetas que manejamos en nuestro FAQ\n",
        "    candidate_labels = [\"Horario\", \"Devoluciones\", \"Envíos\", \"Pagos\"]\n",
        "\n",
        "    # Cargamos un modelo zero-shot multilingüe\n",
        "    clasificador = pipeline(\n",
        "        \"zero-shot-classification\",\n",
        "        model=\"Recognai/bert-base-spanish-wwm-cased-xnli\",\n",
        "        tokenizer=\"Recognai/bert-base-spanish-wwm-cased-xnli\"\n",
        "    )\n",
        "\n",
        "    # Clasificamos\n",
        "    resultado = clasificador(\n",
        "        sequences=pregunta,\n",
        "        candidate_labels=candidate_labels,\n",
        "        hypothesis_template=\"La pregunta está relacionada con {}.\"\n",
        "        # Este template se usa para XNLI; ajusta según la doc.\n",
        "    )\n",
        "    # 'resultado' típicamente es un dict con:\n",
        "    # {\n",
        "    #   'labels': [...],\n",
        "    #   'scores': [...],\n",
        "    #   'sequence': ...\n",
        "    # }\n",
        "    # Donde labels[i] corresponde a la etiqueta candidate_labels[i] y scores[i] a la confianza.\n",
        "\n",
        "    # Tomamos la etiqueta con mayor score\n",
        "    etiqueta_principal = resultado[\"labels\"][0]\n",
        "    confianza = float(resultado[\"scores\"][0])\n",
        "\n",
        "    print(f\"[PLN] Mejor etiqueta: {etiqueta_principal} (confianza={confianza:.2f})\")\n",
        "\n",
        "    # Ahora creamos el motor de reglas e inyectamos el hecho PreguntaUsuario\n",
        "    motor = MotorDeReglasFAQ()\n",
        "    motor.reset()\n",
        "\n",
        "    motor.declare(\n",
        "        PreguntaUsuario(\n",
        "            texto=pregunta,\n",
        "            etiqueta=etiqueta_principal,\n",
        "            score=confianza\n",
        "        )\n",
        "    )\n",
        "\n",
        "    motor.run()\n",
        "\n",
        "    # Leemos la respuesta final de la base de hechos\n",
        "    for fact_id, fact_data in motor.facts.items():\n",
        "        if isinstance(fact_data, Fact) and \"respuesta_final\" in fact_data:\n",
        "            return fact_data[\"respuesta_final\"]\n",
        "\n",
        "    # Por seguridad, en caso de que nada haya funcionado\n",
        "    return \"Lo siento, no tengo respuesta para tu pregunta.\"\n",
        "\n",
        "# ------------------------------------------\n",
        "# 4) Ejemplo de uso\n",
        "# ------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # - Ejemplo 1: Pregunta sobre envíos\n",
        "    pregunta1 = \"¿Cuánto tardan en llegar los productos?\"\n",
        "    resp1 = procesar_pregunta(pregunta1)\n",
        "    print(f\"\\nPREGUNTA: {pregunta1}\\nRESPUESTA: {resp1}\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    # - Ejemplo 2: Pregunta sobre PayPal\n",
        "    pregunta2 = \"¿Aceptan pagos con PayPal?\"\n",
        "    resp2 = procesar_pregunta(pregunta2)\n",
        "    print(f\"\\nPREGUNTA: {pregunta2}\\nRESPUESTA: {resp2}\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    # - Ejemplo 3: Pregunta no contemplada (más ambigua)\n",
        "    pregunta3 = \"¿Cómo puedo realizar un cambio de producto si me arrepiento?\"\n",
        "    resp3 = procesar_pregunta(pregunta3)\n",
        "    print(f\"\\nPREGUNTA: {pregunta3}\\nRESPUESTA: {resp3}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbZhEP4lsWc8",
        "outputId": "9c63d175-4ebf-4c77-e1b4-085a08148e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PLN] Mejor etiqueta: Envíos (confianza=0.83)\n",
            "Regla disparada: Envíos (FAQ).\n",
            "\n",
            "PREGUNTA: ¿Cuánto tardan en llegar los productos?\n",
            "RESPUESTA: Los envíos demoran entre 2 y 5 días laborables, según la ubicación.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PLN] Mejor etiqueta: Pagos (confianza=0.68)\n",
            "Regla fallback activada.\n",
            "\n",
            "PREGUNTA: ¿Aceptan pagos con PayPal?\n",
            "RESPUESTA: Lo siento, no tengo una respuesta clara a tu pregunta. Por favor, contáctanos directamente para más información.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PLN] Mejor etiqueta: Envíos (confianza=0.51)\n",
            "Regla fallback activada.\n",
            "\n",
            "PREGUNTA: ¿Cómo puedo realizar un cambio de producto si me arrepiento?\n",
            "RESPUESTA: Lo siento, no tengo una respuesta clara a tu pregunta. Por favor, contáctanos directamente para más información.\n"
          ]
        }
      ]
    }
  ]
}